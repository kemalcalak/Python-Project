{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["### **Google Drive Balant谋s谋**"],"metadata":{"id":"A_GkxEQ01xay"}},{"cell_type":"code","metadata":{"id":"eh3mJ3A4140I","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690306022150,"user_tz":-180,"elapsed":456854,"user":{"displayName":"ali kemal 莽alak","userId":"00287711100844332297"}},"outputId":"71f43cf0-fbb4-4135-d053-d7c6bfcfe73a"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","metadata":{"id":"7mGmQbAO5pQb"},"source":["### **Kurulumlar**"]},{"cell_type":"code","metadata":{"id":"wbvMlHd_QwMG","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690306038748,"user_tz":-180,"elapsed":12980,"user":{"displayName":"ali kemal 莽alak","userId":"00287711100844332297"}},"outputId":"e8b9b4d8-bada-4e43-c03e-20ff4592f1ef"},"source":["!git clone https://github.com/ultralytics/yolov5\n","%cd yolov5\n","%pip install -qr requirements.txt\n","\n","import torch\n","from IPython.display import Image, clear_output\n","\n","clear_output()\n","print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Setup complete. Using torch 2.0.1+cu118 (Tesla T4)\n"]}]},{"cell_type":"markdown","source":["### **Zipten 谋karma**"],"metadata":{"id":"vr1X8fUF123b"}},{"cell_type":"code","metadata":{"id":"vSLvL3N31qJJ","executionInfo":{"status":"ok","timestamp":1690306060243,"user_tz":-180,"elapsed":13693,"user":{"displayName":"ali kemal 莽alak","userId":"00287711100844332297"}}},"source":["!unzip -q /content/drive/MyDrive/data_f1.zip -d ../"],"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["### **Wandb**"],"metadata":{"id":"slicdR6k17uV"}},{"cell_type":"code","metadata":{"id":"2fLAV42oNb7M","colab":{"base_uri":"https://localhost:8080/","height":191},"executionInfo":{"status":"ok","timestamp":1690306281251,"user_tz":-180,"elapsed":134154,"user":{"displayName":"ali kemal 莽alak","userId":"00287711100844332297"}},"outputId":"2dd3e1c1-5e5d-421a-faa9-1be396a4b85e"},"source":["%pip install -q wandb\n","import wandb\n","wandb.login()"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m\u001b[0m \u001b[32m214.7/214.7 kB\u001b[0m \u001b[31m26.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n","\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n","wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"]},{"name":"stdout","output_type":"stream","text":[" 路路路路路路路路路路\n"]},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":4}]},{"cell_type":"markdown","source":["### **Eitim**"],"metadata":{"id":"PHlaFKIc1gMA"}},{"cell_type":"code","source":["!python train.py --img 640 --batch 1 --epochs 5 --data coco.yaml --weights yolov5x.pt --cache"],"metadata":{"id":"3kJmgmmAkwF2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1690307009997,"user_tz":-180,"elapsed":627658,"user":{"displayName":"ali kemal 莽alak","userId":"00287711100844332297"}},"outputId":"3e47addc-0d83-451b-bdf6-12fe2bbf5f7e"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING 锔 'ultralytics.yolo.v8' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.models.yolo' instead.\n","WARNING 锔 'ultralytics.yolo.utils' is deprecated since '8.0.136' and will be removed in '8.1.0'. Please use 'ultralytics.utils' instead.\n","Note this warning may be related to loading older models. You can update your model to current structure with:\n","    import torch\n","    ckpt = torch.load(\"model.pt\")  # applies to both official and custom models\n","    torch.save(ckpt, \"updated-model.pt\")\n","\n","\u001b[34m\u001b[1mwandb\u001b[0m: WARNING 锔 wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkemalcalak\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","\u001b[34m\u001b[1mtrain: \u001b[0mweights=yolov5x.pt, cfg=, data=coco.yaml, hyp=data/hyps/hyp.scratch-low.yaml, epochs=5, batch_size=1, imgsz=640, rect=False, resume=False, nosave=False, noval=False, noautoanchor=False, noplots=False, evolve=None, bucket=, cache=ram, image_weights=False, device=, multi_scale=False, single_cls=False, optimizer=SGD, sync_bn=False, workers=8, project=runs/train, name=exp, exist_ok=False, quad=False, cos_lr=False, label_smoothing=0.0, patience=100, freeze=[0], save_period=-1, seed=0, local_rank=-1, entity=None, upload_dataset=False, bbox_interval=-1, artifact_alias=latest\n","\u001b[34m\u001b[1mgithub: \u001b[0mup to date with https://github.com/ultralytics/yolov5 \n","YOLOv5  v7.0-196-gacdf73b Python-3.10.6 torch-2.0.1+cu118 CUDA:0 (Tesla T4, 15102MiB)\n","\n","\u001b[34m\u001b[1mhyperparameters: \u001b[0mlr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=0.05, cls=0.5, cls_pw=1.0, obj=1.0, obj_pw=1.0, iou_t=0.2, anchor_t=4.0, fl_gamma=0.0, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, mosaic=1.0, mixup=0.0, copy_paste=0.0\n","\u001b[34m\u001b[1mComet: \u001b[0mrun 'pip install comet_ml' to automatically track and visualize YOLOv5  runs in Comet\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/train', view at http://localhost:6006/\n","\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.15.7\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/content/yolov5/wandb/run-20230725_173313-5u14izdo\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n","\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mdark-donkey-5\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 猸锔 View project at \u001b[34m\u001b[4mhttps://wandb.ai/kemalcalak/YOLOv5\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run at \u001b[34m\u001b[4mhttps://wandb.ai/kemalcalak/YOLOv5/runs/5u14izdo\u001b[0m\n","Downloading https://ultralytics.com/assets/Arial.ttf to /root/.config/Ultralytics/Arial.ttf...\n","100% 755k/755k [00:00<00:00, 93.6MB/s]\n","Downloading https://github.com/ultralytics/yolov5/releases/download/v7.0/yolov5x.pt to yolov5x.pt...\n","100% 166M/166M [00:09<00:00, 18.7MB/s]\n","\n","Overriding model.yaml nc=80 with nc=4\n","\n","                 from  n    params  module                                  arguments                     \n","  0                -1  1      8800  models.common.Conv                      [3, 80, 6, 2, 2]              \n","  1                -1  1    115520  models.common.Conv                      [80, 160, 3, 2]               \n","  2                -1  4    309120  models.common.C3                        [160, 160, 4]                 \n","  3                -1  1    461440  models.common.Conv                      [160, 320, 3, 2]              \n","  4                -1  8   2259200  models.common.C3                        [320, 320, 8]                 \n","  5                -1  1   1844480  models.common.Conv                      [320, 640, 3, 2]              \n","  6                -1 12  13125120  models.common.C3                        [640, 640, 12]                \n","  7                -1  1   7375360  models.common.Conv                      [640, 1280, 3, 2]             \n","  8                -1  4  19676160  models.common.C3                        [1280, 1280, 4]               \n","  9                -1  1   4099840  models.common.SPPF                      [1280, 1280, 5]               \n"," 10                -1  1    820480  models.common.Conv                      [1280, 640, 1, 1]             \n"," 11                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 12           [-1, 6]  1         0  models.common.Concat                    [1]                           \n"," 13                -1  4   5332480  models.common.C3                        [1280, 640, 4, False]         \n"," 14                -1  1    205440  models.common.Conv                      [640, 320, 1, 1]              \n"," 15                -1  1         0  torch.nn.modules.upsampling.Upsample    [None, 2, 'nearest']          \n"," 16           [-1, 4]  1         0  models.common.Concat                    [1]                           \n"," 17                -1  4   1335040  models.common.C3                        [640, 320, 4, False]          \n"," 18                -1  1    922240  models.common.Conv                      [320, 320, 3, 2]              \n"," 19          [-1, 14]  1         0  models.common.Concat                    [1]                           \n"," 20                -1  4   4922880  models.common.C3                        [640, 640, 4, False]          \n"," 21                -1  1   3687680  models.common.Conv                      [640, 640, 3, 2]              \n"," 22          [-1, 10]  1         0  models.common.Concat                    [1]                           \n"," 23                -1  4  19676160  models.common.C3                        [1280, 1280, 4, False]        \n"," 24      [17, 20, 23]  1     60561  models.yolo.Detect                      [4, [[10, 13, 16, 30, 33, 23], [30, 61, 62, 45, 59, 119], [116, 90, 156, 198, 373, 326]], [320, 640, 1280]]\n","Model summary: 445 layers, 86238001 parameters, 86238001 gradients, 204.7 GFLOPs\n","\n","Transferred 739/745 items from yolov5x.pt\n","\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n","\u001b[34m\u001b[1moptimizer:\u001b[0m SGD(lr=0.01) with parameter groups 123 weight(decay=0.0), 126 weight(decay=0.0005), 126 bias\n","\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01), CLAHE(p=0.01, clip_limit=(1, 4.0), tile_grid_size=(8, 8))\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/data_f1/labels/train... 785 images, 0 backgrounds, 0 corrupt: 100% 785/785 [00:00<00:00, 1759.75it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/data_f1/labels/train.cache\n","\u001b[34m\u001b[1mtrain: \u001b[0mCaching images (0.5GB ram): 100% 785/785 [00:21<00:00, 35.75it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/data_f1/labels/val... 78 images, 0 backgrounds, 0 corrupt: 100% 78/78 [00:00<00:00, 664.73it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/data_f1/labels/val.cache\n","\u001b[34m\u001b[1mval: \u001b[0mCaching images (0.1GB ram): 100% 78/78 [00:02<00:00, 30.97it/s]\n","\n","\u001b[34m\u001b[1mAutoAnchor: \u001b[0m3.21 anchors/target, 1.000 Best Possible Recall (BPR). Current anchors are a good fit to dataset \n","Plotting labels to runs/train/exp/labels.jpg... \n","Image sizes 640 train, 640 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1mruns/train/exp\u001b[0m\n","Starting training for 5 epochs...\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        0/4      2.78G    0.05314    0.03052    0.03119          2        640: 100% 785/785 [01:44<00:00,  7.53it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 39/39 [00:03<00:00, 12.41it/s]\n","                   all         78        128      0.163       0.43      0.196     0.0889\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        1/4      2.78G     0.0383     0.0202    0.02918          4        640: 100% 785/785 [01:35<00:00,  8.25it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 39/39 [00:01<00:00, 21.70it/s]\n","                   all         78        128      0.184      0.483      0.278       0.17\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        2/4      2.78G    0.03337    0.01677    0.02764          4        640: 100% 785/785 [01:33<00:00,  8.35it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 39/39 [00:01<00:00, 20.02it/s]\n","                   all         78        128      0.274      0.587      0.335      0.154\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        3/4      2.78G    0.02674     0.0146    0.02495          4        640: 100% 785/785 [01:30<00:00,  8.64it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 39/39 [00:02<00:00, 17.51it/s]\n","                   all         78        128      0.419      0.691      0.558      0.292\n","\n","      Epoch    GPU_mem   box_loss   obj_loss   cls_loss  Instances       Size\n","        4/4      2.79G    0.02631    0.01433    0.02286          4        640: 100% 785/785 [01:31<00:00,  8.60it/s]\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 39/39 [00:01<00:00, 21.26it/s]\n","                   all         78        128      0.615      0.645       0.67      0.411\n","\n","5 epochs completed in 0.146 hours.\n","Optimizer stripped from runs/train/exp/weights/last.pt, 173.1MB\n","Optimizer stripped from runs/train/exp/weights/best.pt, 173.1MB\n","\n","Validating runs/train/exp/weights/best.pt...\n","Fusing layers... \n","Model summary: 322 layers, 86193601 parameters, 0 gradients, 203.8 GFLOPs\n","                 Class     Images  Instances          P          R      mAP50   mAP50-95: 100% 39/39 [00:02<00:00, 18.35it/s]\n","                   all         78        128      0.607      0.646       0.67      0.411\n","               Ferrari         78         31      0.527      0.683      0.739      0.478\n","               Mclaren         78         30      0.682      0.633      0.715      0.399\n","              Mercedes         78         31      0.525      0.935      0.708      0.406\n","               Redbull         78         36      0.695      0.333      0.519       0.36\n","Results saved to \u001b[1mruns/train/exp\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Waiting for W&B process to finish... \u001b[32m(success).\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run history:\n","\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 \n","\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 \n","\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision \n","\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall \n","\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss \n","\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss \n","\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss \n","\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss \n","\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss \n","\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss \n","\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 \n","\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 \n","\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 \n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m: Run summary:\n","\u001b[34m\u001b[1mwandb\u001b[0m:           best/epoch 4\n","\u001b[34m\u001b[1mwandb\u001b[0m:         best/mAP_0.5 0.66994\n","\u001b[34m\u001b[1mwandb\u001b[0m:    best/mAP_0.5:0.95 0.41054\n","\u001b[34m\u001b[1mwandb\u001b[0m:       best/precision 0.61542\n","\u001b[34m\u001b[1mwandb\u001b[0m:          best/recall 0.64489\n","\u001b[34m\u001b[1mwandb\u001b[0m:      metrics/mAP_0.5 0.67019\n","\u001b[34m\u001b[1mwandb\u001b[0m: metrics/mAP_0.5:0.95 0.41058\n","\u001b[34m\u001b[1mwandb\u001b[0m:    metrics/precision 0.60713\n","\u001b[34m\u001b[1mwandb\u001b[0m:       metrics/recall 0.64633\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train/box_loss 0.02631\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train/cls_loss 0.02286\n","\u001b[34m\u001b[1mwandb\u001b[0m:       train/obj_loss 0.01433\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val/box_loss 0.02031\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val/cls_loss 0.01613\n","\u001b[34m\u001b[1mwandb\u001b[0m:         val/obj_loss 0.01164\n","\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr0 0.00406\n","\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr1 0.00406\n","\u001b[34m\u001b[1mwandb\u001b[0m:                x/lr2 0.00406\n","\u001b[34m\u001b[1mwandb\u001b[0m: \n","\u001b[34m\u001b[1mwandb\u001b[0m:  View run \u001b[33mdark-donkey-5\u001b[0m at: \u001b[34m\u001b[4mhttps://wandb.ai/kemalcalak/YOLOv5/runs/5u14izdo\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: 锔 View job at \u001b[34m\u001b[4mhttps://wandb.ai/kemalcalak/YOLOv5/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjgxODYxMjU1/version_details/v1\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: Synced 5 W&B file(s), 17 media file(s), 3 artifact file(s) and 0 other file(s)\n","\u001b[34m\u001b[1mwandb\u001b[0m: Find logs at: \u001b[35m\u001b[1m./wandb/run-20230725_173313-5u14izdo/logs\u001b[0m\n","\u001b[34m\u001b[1mwandb\u001b[0m: WARNING 锔 wandb is deprecated and will be removed in a future release. See supported integrations at https://github.com/ultralytics/yolov5#integrations.\n"]}]},{"cell_type":"markdown","source":["### **Test**"],"metadata":{"id":"xPyUpLX91lfd"}},{"cell_type":"code","metadata":{"id":"zR9ZbuQCH7FX"},"source":["!python detect.py --weights /content/drive/MyDrive/data-weights/last.pt --img 640 --conf 0.25 --source /content/drive/MyDrive/videoplayback.mp4"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### **Tensorboard**"],"metadata":{"id":"vt4fCg6W1cqS"}},{"cell_type":"code","metadata":{"id":"bOy5KI2ncnWd"},"source":["%load_ext tensorboard\n","%tensorboard --logdir runs/train"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"15glLzbQx5u0"},"source":["### **G枚rselletirme**"]},{"cell_type":"code","metadata":{"id":"MDznIqPF7nk3"},"source":["from utils.plots import plot_results\n","plot_results(\"/content/yolov5/runs/train/exp3/results.csv\")\n","Image(filename='/content/yolov5/runs/train/exp3/results.png', width=800)"],"execution_count":null,"outputs":[]}]}