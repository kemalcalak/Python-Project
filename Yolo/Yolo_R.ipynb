{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8quyH0gCuTeC",
        "outputId": "80654446-d19f-49ab-a8cf-245312232fd2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XiZzvTOKsB4_",
        "outputId": "6655b8f6-51fc-40e0-ce2c-be71c7594841"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'YOLOR-----Object-Detection-in-Custom-Data-with-YoloR'...\n",
            "remote: Enumerating objects: 1834, done.\u001b[K\n",
            "remote: Total 1834 (delta 0), reused 0 (delta 0), pack-reused 1834\u001b[K\n",
            "Receiving objects: 100% (1834/1834), 274.20 MiB | 12.88 MiB/s, done.\n",
            "Resolving deltas: 100% (37/37), done.\n",
            "Checking out files: 100% (1779/1779), done.\n",
            "/content/yolor\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/yasarniyazoglu/YOLOR-----Object-Detection-in-Custom-Data-with-YoloR.git\n",
        "%mv YOLOR-----Object-Detection-in-Custom-Data-with-YoloR yolor\n",
        "%cd yolor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBMz3IVGsEIm",
        "outputId": "2e7f2f11-bf07-461d-cc1c-4f999645be6e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 596 kB 11.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 776.7 MB 4.5 kB/s \n",
            "\u001b[K     |████████████████████████████████| 12.7 MB 28.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 37.1 MB/s \n",
            "\u001b[?25h  Building wheel for pycocotools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.12.0 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\n",
            "torchaudio 0.11.0+cu113 requires torch==1.11.0, but you have torch 1.7.0 which is incompatible.\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -qr requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN7PiRzzsEK8",
        "outputId": "d5beec8f-dafe-48d5-a85d-a025b0f9189b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'mish-cuda'...\n",
            "remote: Enumerating objects: 195, done.\u001b[K\n",
            "remote: Counting objects: 100% (88/88), done.\u001b[K\n",
            "remote: Compressing objects: 100% (75/75), done.\u001b[K\n",
            "remote: Total 195 (delta 7), reused 79 (delta 3), pack-reused 107\u001b[K\n",
            "Receiving objects: 100% (195/195), 208.77 KiB | 7.46 MiB/s, done.\n",
            "Resolving deltas: 100% (56/56), done.\n",
            "/content/yolor/mish-cuda\n",
            "HEAD is now at 6f38976 Update README.md\n",
            "/usr/lib/python3.7/distutils/extension.py:131: UserWarning: Unknown Extension options: 'headers'\n",
            "  warnings.warn(msg)\n",
            "running build\n",
            "running build_py\n",
            "creating build\n",
            "creating build/lib.linux-x86_64-3.7\n",
            "creating build/lib.linux-x86_64-3.7/mish_cuda\n",
            "copying src/mish_cuda/__init__.py -> build/lib.linux-x86_64-3.7/mish_cuda\n",
            "running egg_info\n",
            "creating src/mish_cuda.egg-info\n",
            "writing src/mish_cuda.egg-info/PKG-INFO\n",
            "writing dependency_links to src/mish_cuda.egg-info/dependency_links.txt\n",
            "writing requirements to src/mish_cuda.egg-info/requires.txt\n",
            "writing top-level names to src/mish_cuda.egg-info/top_level.txt\n",
            "writing manifest file 'src/mish_cuda.egg-info/SOURCES.txt'\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/cpp_extension.py:339: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "adding license file 'LICENSE'\n",
            "writing manifest file 'src/mish_cuda.egg-info/SOURCES.txt'\n",
            "running build_ext\n",
            "building 'mish_cuda._C' extension\n",
            "creating build/temp.linux-x86_64-3.7\n",
            "creating build/temp.linux-x86_64-3.7/csrc\n",
            "creating build/temp.linux-x86_64-3.7/csrc/cpu\n",
            "creating build/temp.linux-x86_64-3.7/csrc/cuda\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c csrc/cpu/mish_cpu.cpp -o build/temp.linux-x86_64-3.7/csrc/cpu/mish_cpu.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:149:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/CPUApplyUtils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kcsrc/cpu/mish_cpu.cpp:3\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n",
            " #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            " \n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 -fPIC -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c csrc/cuda/mish_cuda.cpp -o build/temp.linux-x86_64-3.7/csrc/cuda/mish_cuda.o -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++14\n",
            "In file included from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/Parallel.h:149:0\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/utils.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn/cloneable.h:5\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/nn.h:3\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include/torch/all.h:12\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/torch/extension.h:4\u001b[m\u001b[K,\n",
            "                 from \u001b[01m\u001b[Kcsrc/cuda/mish_cuda.cpp:2\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[K/usr/local/lib/python3.7/dist-packages/torch/include/ATen/ParallelOpenMP.h:84:0:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[Kignoring #pragma omp parallel [\u001b[01;35m\u001b[K-Wunknown-pragmas\u001b[m\u001b[K]\n",
            " #pragma omp parallel for if ((end - begin) >= grain_size)\n",
            " \n",
            "/usr/local/cuda/bin/nvcc -I/usr/local/lib/python3.7/dist-packages/torch/include -I/usr/local/lib/python3.7/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.7/dist-packages/torch/include/TH -I/usr/local/lib/python3.7/dist-packages/torch/include/THC -I/usr/local/cuda/include -I/usr/include/python3.7m -c csrc/cuda/mish_kernel.cu -o build/temp.linux-x86_64-3.7/csrc/cuda/mish_kernel.o -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr --compiler-options '-fPIC' --expt-extended-lambda -DTORCH_API_INCLUDE_EXTENSION_H -DTORCH_EXTENSION_NAME=_C -D_GLIBCXX_USE_CXX11_ABI=0 -gencode=arch=compute_37,code=sm_37 -std=c++14\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/boxing/impl/boxing.h(100): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/op_registration/op_whitelist.h(39): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/boxing/impl/boxing.h(100): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "/usr/local/lib/python3.7/dist-packages/torch/include/ATen/core/op_registration/op_whitelist.h(39): warning: integer conversion resulted in a change of sign\n",
            "\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 -Wl,-Bsymbolic-functions -g -fwrapv -O2 -g -fstack-protector-strong -Wformat -Werror=format-security -Wdate-time -D_FORTIFY_SOURCE=2 build/temp.linux-x86_64-3.7/csrc/cpu/mish_cpu.o build/temp.linux-x86_64-3.7/csrc/cuda/mish_cuda.o build/temp.linux-x86_64-3.7/csrc/cuda/mish_kernel.o -L/usr/local/lib/python3.7/dist-packages/torch/lib -L/usr/local/cuda/lib64 -lc10 -ltorch -ltorch_cpu -ltorch_python -lcudart -lc10_cuda -ltorch_cuda -o build/lib.linux-x86_64-3.7/mish_cuda/_C.cpython-37m-x86_64-linux-gnu.so\n",
            "running install\n",
            "running bdist_egg\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "creating build/bdist.linux-x86_64/egg/mish_cuda\n",
            "copying build/lib.linux-x86_64-3.7/mish_cuda/_C.cpython-37m-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg/mish_cuda\n",
            "copying build/lib.linux-x86_64-3.7/mish_cuda/__init__.py -> build/bdist.linux-x86_64/egg/mish_cuda\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mish_cuda/__init__.py to __init__.cpython-37.pyc\n",
            "creating stub loader for mish_cuda/_C.cpython-37m-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/mish_cuda/_C.py to _C.cpython-37.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/not-zip-safe -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/requires.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying src/mish_cuda.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "creating dist\n",
            "creating 'dist/mish_cuda-0.0.3-py3.7-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing mish_cuda-0.0.3-py3.7-linux-x86_64.egg\n",
            "creating /usr/local/lib/python3.7/dist-packages/mish_cuda-0.0.3-py3.7-linux-x86_64.egg\n",
            "Extracting mish_cuda-0.0.3-py3.7-linux-x86_64.egg to /usr/local/lib/python3.7/dist-packages\n",
            "Adding mish-cuda 0.0.3 to easy-install.pth file\n",
            "\n",
            "Installed /usr/local/lib/python3.7/dist-packages/mish_cuda-0.0.3-py3.7-linux-x86_64.egg\n",
            "Processing dependencies for mish-cuda==0.0.3\n",
            "Searching for torch==1.7.0\n",
            "Best match: torch 1.7.0\n",
            "Adding torch 1.7.0 to easy-install.pth file\n",
            "Installing convert-caffe2-to-onnx script to /usr/local/bin\n",
            "Installing convert-onnx-to-caffe2 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for typing-extensions==4.2.0\n",
            "Best match: typing-extensions 4.2.0\n",
            "Adding typing-extensions 4.2.0 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for dataclasses==0.6\n",
            "Best match: dataclasses 0.6\n",
            "Adding dataclasses 0.6 to easy-install.pth file\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for numpy==1.21.6\n",
            "Best match: numpy 1.21.6\n",
            "Adding numpy 1.21.6 to easy-install.pth file\n",
            "Installing f2py script to /usr/local/bin\n",
            "Installing f2py3 script to /usr/local/bin\n",
            "Installing f2py3.7 script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Searching for future==0.16.0\n",
            "Best match: future 0.16.0\n",
            "Adding future 0.16.0 to easy-install.pth file\n",
            "Installing futurize script to /usr/local/bin\n",
            "Installing pasteurize script to /usr/local/bin\n",
            "\n",
            "Using /usr/local/lib/python3.7/dist-packages\n",
            "Finished processing dependencies for mish-cuda==0.0.3\n",
            "/content/yolor\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/JunnYu/mish-cuda\n",
        "%cd mish-cuda\n",
        "!git reset --hard 6f38976064cbcc4782f4212d7c0c5f6dd5e315a8\n",
        "!python setup.py build install\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Me-8PzKsENW",
        "outputId": "5607ca14-9fff-4f9f-e195-c9dfd5156859"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'pytorch_wavelets'...\n",
            "remote: Enumerating objects: 972, done.\u001b[K\n",
            "remote: Counting objects: 100% (136/136), done.\u001b[K\n",
            "remote: Compressing objects: 100% (91/91), done.\u001b[K\n",
            "remote: Total 972 (delta 75), reused 89 (delta 45), pack-reused 836\u001b[K\n",
            "Receiving objects: 100% (972/972), 6.80 MiB | 15.10 MiB/s, done.\n",
            "Resolving deltas: 100% (659/659), done.\n",
            "/content/yolor/pytorch_wavelets\n",
            "Processing /content/yolor/pytorch_wavelets\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pytorch-wavelets==1.3.0) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pytorch-wavelets==1.3.0) (1.15.0)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pytorch-wavelets==1.3.0) (1.7.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-wavelets==1.3.0) (4.2.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-wavelets==1.3.0) (0.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch->pytorch-wavelets==1.3.0) (0.16.0)\n",
            "Building wheels for collected packages: pytorch-wavelets\n",
            "  Building wheel for pytorch-wavelets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytorch-wavelets: filename=pytorch_wavelets-1.3.0-py3-none-any.whl size=54869 sha256=d4c48ba65482f6b27278d230769af30d22b3d1c1a4231ef3fa221bf972a6f80e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-bvl3k0wv/wheels/68/d6/0a/629cb6c68e1577155ab73a47758996d9ab26f15ba622561e28\n",
            "Successfully built pytorch-wavelets\n",
            "Installing collected packages: pytorch-wavelets\n",
            "Successfully installed pytorch-wavelets-1.3.0\n",
            "/content/yolor\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/fbcotter/pytorch_wavelets\n",
        "%cd pytorch_wavelets\n",
        "!pip install .\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYJLTn3osEP1"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/drive/MyDrive/data-weights/data_f1.zip -d ../"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kVdjvCtRsESY",
        "outputId": "3b14b68e-da2b-4e40-cc39-7ea688e05677"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/yolor\n",
            "awk: cannot open ./cookie (No such file or directory)\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2228    0  2228    0     0   3448      0 --:--:-- --:--:-- --:--:--  3443\n",
            "rm: cannot remove './cookie': No such file or directory\n",
            "awk: cannot open ./cookie (No such file or directory)\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  2228    0  2228    0     0   3611      0 --:--:-- --:--:-- --:--:--  3611\n",
            "rm: cannot remove './cookie': No such file or directory\n"
          ]
        }
      ],
      "source": [
        "%cd /content/yolor\n",
        "!bash scripts/get_pretrain.sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "_OLvuC_vt1gN",
        "outputId": "9dc63385-06d2-4078-b2c7-a36523dbb97f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 1.6 MB 9.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 97 kB 7.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 170 kB 64.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 133 kB 65.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 63 kB 2.3 MB/s \n",
            "\u001b[?25h  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "data": {
            "application/javascript": "\n        window._wandbApiKey = new Promise((resolve, reject) => {\n            function loadScript(url) {\n            return new Promise(function(resolve, reject) {\n                let newScript = document.createElement(\"script\");\n                newScript.onerror = reject;\n                newScript.onload = resolve;\n                document.body.appendChild(newScript);\n                newScript.src = url;\n            });\n            }\n            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n            const iframe = document.createElement('iframe')\n            iframe.style.cssText = \"width:0;height:0;border:none\"\n            document.body.appendChild(iframe)\n            const handshake = new Postmate({\n                container: iframe,\n                url: 'https://wandb.ai/authorize'\n            });\n            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n            handshake.then(function(child) {\n                child.on('authorize', data => {\n                    clearTimeout(timeout)\n                    resolve(data)\n                });\n            });\n            })\n        });\n    ",
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 7,
          "metadata": {
            "tags": []
          },
          "output_type": "execute_result"
        }
      ],
      "source": [
        "%pip install -q wandb\n",
        "import wandb\n",
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-IWXFBEsEUX",
        "outputId": "423c4895-0209-4070-d210-31b53adbc0bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/yolor\n",
            "Using torch 1.7.0 CUDA:0 (Tesla K80, 11441MB)\n",
            "\n",
            "Namespace(adam=False, batch_size=1, bucket='', cache_images=False, cfg='/content/yolor/customyolor.cfg', data='/content/yolor/yolor.yaml', device='0', epochs=30, evolve=False, exist_ok=False, global_rank=-1, hyp='/content/yolor/data/hyp.scratch.1280.yaml', image_weights=False, img_size=[416, 416], local_rank=-1, log_imgs=16, multi_scale=False, name='yolor_p6', noautoanchor=False, nosave=False, notest=False, project='runs/train', rect=False, resume=False, save_dir='runs/train/yolor_p62', single_cls=False, sync_bn=False, total_batch_size=1, weights='', workers=8, world_size=1)\n",
            "Start Tensorboard with \"tensorboard --logdir runs/train\", view at http://localhost:6006/\n",
            "NumExpr defaulting to 2 threads.\n",
            "Hyperparameters {'lr0': 0.01, 'lrf': 0.2, 'momentum': 0.937, 'weight_decay': 0.0005, 'warmup_epochs': 3.0, 'warmup_momentum': 0.8, 'warmup_bias_lr': 0.1, 'box': 0.05, 'cls': 0.5, 'cls_pw': 1.0, 'obj': 1.0, 'obj_pw': 1.0, 'iou_t': 0.2, 'anchor_t': 4.0, 'fl_gamma': 0.0, 'hsv_h': 0.015, 'hsv_s': 0.7, 'hsv_v': 0.4, 'degrees': 0.0, 'translate': 0.5, 'scale': 0.5, 'shear': 0.0, 'perspective': 0.0, 'flipud': 0.0, 'fliplr': 0.5, 'mosaic': 1.0, 'mixup': 0.0}\n",
            "Model Summary: 665 layers, 36854616 parameters, 36854616 gradients, 80.410315000 GFLOPS\n",
            "Optimizer groups: 145 .bias, 145 conv.weight, 149 other\n",
            "WARNING: --img-size 416 must be multiple of max stride 64, updating to 448\n",
            "WARNING: --img-size 416 must be multiple of max stride 64, updating to 448\n",
            "Scanning images: 100% 785/785 [00:00<00:00, 5100.83it/s]\n",
            "Scanning labels /content/data_f1/labels/train.cache3 (785 found, 0 missing, 0 empty, 0 duplicate, for 785 images): 785it [00:00, 9848.67it/s]\n",
            "Scanning images: 100% 78/78 [00:00<00:00, 6453.16it/s]\n",
            "Scanning labels /content/data_f1/labels/val.cache3 (78 found, 0 missing, 0 empty, 0 duplicate, for 78 images): 78it [00:00, 10070.98it/s]\n",
            "Image sizes 448 train, 448 test\n",
            "Using 0 dataloader workers\n",
            "Logging results to runs/train/yolor_p62\n",
            "Starting training for 30 epochs...\n",
            "\n",
            "     Epoch   gpu_mem       box       obj       cls     total   targets  img_size\n",
            "      0/29     1.51G   0.08393   0.05417   0.03433    0.1724         1       448:   6% 44/785 [00:23<06:39,  1.85it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"train.py\", line 537, in <module>\n",
            "    train(hyp, opt, device, tb_writer, wandb)\n",
            "  File \"train.py\", line 262, in train\n",
            "    for i, (imgs, targets, paths, _) in pbar:  # batch -------------------------------------------------------------\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/tqdm/std.py\", line 1195, in __iter__\n",
            "    for obj in iterable:\n",
            "  File \"/content/yolor/utils/datasets.py\", line 128, in __iter__\n",
            "    yield next(self.iterator)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 435, in __next__\n",
            "    data = self._next_data()\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\", line 475, in _next_data\n",
            "    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in fetch\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\", line 44, in <listcomp>\n",
            "    data = [self.dataset[idx] for idx in possibly_batched_index]\n",
            "  File \"/content/yolor/utils/datasets.py\", line 554, in __getitem__\n",
            "    img, labels = load_mosaic(self, index)\n",
            "  File \"/content/yolor/utils/datasets.py\", line 969, in load_mosaic\n",
            "    img, _, (h, w) = load_image(self, index)\n",
            "  File \"/content/yolor/utils/datasets.py\", line 929, in load_image\n",
            "    img = cv2.imread(path)  # BGR\n",
            "KeyboardInterrupt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "# train\n",
        "%cd /content/yolor\n",
        "!python train.py --batch-size 1 --img 416 416 --data '/content/yolor/yolor.yaml' --cfg /content/yolor/customyolor.cfg --weights '/content/yolor/yolor_p6.pt' --device 0 --name yolor_p6 --hyp '/content/yolor/data/hyp.scratch.1280.yaml' --epochs 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CohmE27LsEaA"
      },
      "outputs": [],
      "source": [
        "# tensorboard\n",
        "%load_ext tensorboard\n",
        "%tensorboard --logdir runs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dLNijgFxsEW9"
      },
      "outputs": [],
      "source": [
        "# test\n",
        "!python detect.py --weights \"best.pt\" --conf 0.25 --source /content/drive/MyDrive/videoplayback.mp4 --names /content/yolor/data/coco.names  --cfg customyolor.cfg"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
